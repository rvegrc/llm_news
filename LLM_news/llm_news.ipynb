{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c271f67e5f6049b7b4b5e67c65c46975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546974394f8644e7a317a14c9dafd549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "gpu_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"models/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 50},\n",
    ")\n",
    "\n",
    "\n",
    "cpu_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"models/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 50},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step. Electroencephalography (EEG) is a test that measures the electrical activity of the brain.\n",
      "\n",
      "1. The brain is made up of billions of nerve cells, or neurons, that communicate with each other through electrical signals\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "gpu_chain = prompt | gpu_llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(gpu_chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step. Electroencephalography, or EEG, is a method used to record electrical activity in the brain. It works by placing small sensors, called electrodes, on the scalp. These electrodes detect the electrical signals produced by the brain's neurons as they communicate\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "cpu_chain = prompt | cpu_llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(cpu_chain.invoke({\"question\": question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
