{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞—á–∞:\n",
    "–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É —Ä–∞–±–æ—Ç—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –æ—Ü–µ–Ω–∏—Ç—å –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ç–µ—Ö —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.\n",
    "¬†\n",
    "–ñ–µ–ª–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\n",
    "–ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ -\n",
    "—Å —ç—Ç–∞–ª–æ–Ω–æ–º —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏;\n",
    "—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã (—Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç—Ç–∞–ª–æ–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–µ–∫—Å—Ç–∞, –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π);\n",
    "–æ—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å;\n",
    "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from operator import itemgetter\n",
    "\n",
    "# üì¶ –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# üöÄ LangChain –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import (\n",
    "    PydanticOutputParser,\n",
    "    StructuredOutputParser,\n",
    "    OutputFixingParser,\n",
    ")\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnablePassthrough,\n",
    "    chain,\n",
    "    RunnableConfig,\n",
    ")\n",
    "\n",
    "# üîé Graph Retriever\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "from graph_retriever.strategies import Eager\n",
    "from langchain.schema import Document  # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç Document\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "from langchain_core.documents import Document\n",
    "from keybert import KeyBERT\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bb01b503c44a12850fd7a928273221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6d0609f32142d1942062359b7398b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import Dict, Any, List, Optional\n",
    "\n",
    "# from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "# from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "# from langchain.output_parsers import OutputFixingParser\n",
    "# from langchain_core.tools import tool\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "# from langchain_huggingface.llms import HuggingFacePipeline\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# gpu_llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"../models/Mistral-7B-Instruct-v0.3\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\": 50},\n",
    "# )\n",
    "\n",
    "\n",
    "# cpu_llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"../models/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\": 50},\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step.\n",
      "\n",
      "Electroencephalography (EEG) is a technique used to record the electrical activity of the brain.\n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "1. 'Electro': Related to electricity.\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "gpu_chain = prompt | gpu_llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(gpu_chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step. Electroencephalography, or EEG, is a method used to record electrical activity in the brain. It works by placing small sensors, called electrodes, on the scalp. These electrodes detect the electrical signals produced by the brain's neurons as they communicate\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "cpu_chain = prompt | cpu_llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(cpu_chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_web = pd.read_csv(\"tmp/data_test_web.csv\")\n",
    "data_test_web = data_test_web.dropna(subset=[\"web_text\"], axis='raws').reset_index(drop=True)\n",
    "data_test_web.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
